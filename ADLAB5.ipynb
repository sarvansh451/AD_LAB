{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_jaStr8OTh6z"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the digits dataset\n",
        "digits = load_digits()\n",
        "\n",
        "# Flattened features (X) and labels (y)\n",
        "X = digits.data\n",
        "y = digits.target\n"
      ],
      "metadata": {
        "id": "9GK5qUwkWZhj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define logistic regression model\n",
        "logreg = LogisticRegression(max_iter=5000)"
      ],
      "metadata": {
        "id": "z3vOt5XbWfJ8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define hyperparameter grid\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10],  # Regularization strength\n",
        "    'solver': ['lbfgs', 'saga'],  # Optimization algorithm\n",
        "    'penalty': ['l2']  # Type of regularization\n",
        "}\n"
      ],
      "metadata": {
        "id": "KesCkyHnWif8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use GridSearchCV to tune hyperparameters\n",
        "grid_search = GridSearchCV(logreg, param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = best_model.predict(X_test)"
      ],
      "metadata": {
        "id": "M76CSjeeWlW_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n"
      ],
      "metadata": {
        "id": "Srwkr6WpWnhP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store metrics in an array\n",
        "metrics_array = [accuracy, f1, precision, recall]\n",
        "print(metrics_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNNyapzZWuk_",
        "outputId": "a4422ab1-17e2-40d6-c9fa-4c04d8d057b6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.9648148148148148, 0.9649170553084626, 0.9653668356900756, 0.9648148148148148]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print hyperparameter ranges and results\n",
        "print(\"Hyperparameter Ranges:\")\n",
        "for param, values in param_grid.items():\n",
        "    print(f\"{param}: {values}\")\n",
        "\n",
        "print(\"\\nBest Hyperparameters:\")\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "print(\"\\nPerformance Metrics:\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"F1 Score: {f1}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"Metrics Array: {metrics_array}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-rMVhfRWy-c",
        "outputId": "02a9223d-a63a-4b55-e937-5dfde2d73aaa"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hyperparameter Ranges:\n",
            "C: [0.01, 0.1, 1, 10]\n",
            "solver: ['lbfgs', 'saga']\n",
            "penalty: ['l2']\n",
            "\n",
            "Best Hyperparameters:\n",
            "{'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "\n",
            "Performance Metrics:\n",
            "Accuracy: 0.9648148148148148\n",
            "F1 Score: 0.9649170553084626\n",
            "Precision: 0.9653668356900756\n",
            "Recall: 0.9648148148148148\n",
            "Metrics Array: [0.9648148148148148, 0.9649170553084626, 0.9653668356900756, 0.9648148148148148]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WeWrzrJ0W2uD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}